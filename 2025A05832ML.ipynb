{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "840f5c9b-e4e6-4e6b-bc2e-408ecf8c8232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, recall_score, f1_score,\n",
    "    matthews_corrcoef, confusion_matrix, classification_report\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aad46349-1429-4ed7-a851-50e8d8b2af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost (install: pip install xgboost)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGBOOST_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a7160e0-7b1f-42ac-bd06-0fc4f6936ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    \"\"\"Build preprocessing: impute, one-hot encode categoricals, scale numerics.\"\"\"\n",
    "    cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "    numeric_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_pipe, num_cols),\n",
    "            (\"cat\", categorical_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    return preprocessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc5d2366-8523-4bcb-806f-1c5ee966ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test) -> dict:\n",
    "    \"\"\"Compute required metrics for binary classification.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Get probability scores for AUC if possible\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        # decision_function can be used for AUC\n",
    "        scores = model.decision_function(X_test)\n",
    "        # normalize to 0..1 (not required, but keeps it stable)\n",
    "        y_proba = (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)\n",
    "    else:\n",
    "        y_proba = None\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "        \"Precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "        \"Recall\": float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "        \"F1\": float(f1_score(y_test, y_pred, zero_division=0)),\n",
    "        \"MCC\": float(matthews_corrcoef(y_test, y_pred)),\n",
    "    }\n",
    "\n",
    "    if y_proba is not None:\n",
    "        metrics[\"AUC\"] = float(roc_auc_score(y_test, y_proba))\n",
    "    else:\n",
    "        metrics[\"AUC\"] = np.nan\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04237642-af9d-434c-91c8-988a9e5aec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ====== CHANGE THIS PATH IF NEEDED ======\n",
    "    csv_path = \"bank/bank.csv\"\n",
    "    # =======================================\n",
    "\n",
    "    df = pd.read_csv(csv_path, sep=';')\n",
    "\n",
    "    if \"y\" not in df.columns:\n",
    "        raise ValueError(\"Target column 'y' not found. Please rename your target column to 'y'.\")\n",
    "\n",
    "    # Convert target to 0/1\n",
    "    y = df[\"y\"].astype(str).str.lower().map({\"no\": 0, \"yes\": 1})\n",
    "    if y.isna().any():\n",
    "        raise ValueError(\"Target 'y' must contain only 'yes'/'no' values.\")\n",
    "\n",
    "    X = df.drop(columns=[\"y\"])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    preprocessor = build_preprocessor(X_train)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=2000),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "        # GaussianNB needs dense input; we'll handle via a special pipeline below\n",
    "        \"Naive Bayes (Gaussian)\": GaussianNB(),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            n_estimators=300, random_state=42, n_jobs=-1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    if XGBOOST_AVAILABLE:\n",
    "        models[\"XGBoost\"] = XGBClassifier(\n",
    "            n_estimators=400,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=42,\n",
    "            eval_metric=\"logloss\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"xgboost not installed. Install with: pip install xgboost\")\n",
    "        print(\"   Skipping XGBoost training.\")\n",
    "\n",
    "    os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, clf in models.items():\n",
    "        if \"Naive Bayes\" in name:\n",
    "            # GaussianNB expects dense arrays; convert sparse to dense using a small wrapper\n",
    "            pipeline = Pipeline(steps=[\n",
    "                (\"prep\", preprocessor),\n",
    "                (\"to_dense\", FunctionTransformerDense()),\n",
    "                (\"model\", clf)\n",
    "            ])\n",
    "        else:\n",
    "            pipeline = Pipeline(steps=[\n",
    "                (\"prep\", preprocessor),\n",
    "                (\"model\", clf)\n",
    "            ])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        metrics = evaluate_model(pipeline, X_test, y_test)\n",
    "        metrics[\"Model\"] = name\n",
    "        results.append(metrics)\n",
    "\n",
    "        # Save model\n",
    "        joblib.dump(pipeline, f\"model/{safe_filename(name)}.pkl\")\n",
    "        print(f\" Trained & saved: {name}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)[\n",
    "        [\"Model\", \"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1\", \"MCC\"]\n",
    "    ].sort_values(by=\"AUC\", ascending=False)\n",
    "\n",
    "    print(\"\\n===== METRICS COMPARISON TABLE =====\")\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    # Print confusion matrix + report for best model\n",
    "    best_model_name = results_df.iloc[0][\"Model\"]\n",
    "    best_model = joblib.load(f\"model/{safe_filename(best_model_name)}.pkl\")\n",
    "\n",
    "    y_pred_best = best_model.predict(X_test)\n",
    "    print(f\"\\n===== BEST MODEL: {best_model_name} =====\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred_best))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_best, zero_division=0))\n",
    "\n",
    "    results_df.to_csv(\"model/model_metrics.csv\", index=False)\n",
    "    print(\"\\n Saved metrics table to: model/model_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a208cd37-eceb-488d-b062-46e9761dc98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_filename(name: str) -> str:\n",
    "    return (\n",
    "        name.lower()\n",
    "        .replace(\" \", \"_\")\n",
    "        .replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\"/\", \"_\")\n",
    "        .replace(\"-\", \"_\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82f70220-3364-45e7-a81d-8b78ef9dcfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionTransformerDense:\n",
    "    \"\"\"Turns sparse matrix into dense for GaussianNB.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # If already dense, keep it\n",
    "        if hasattr(X, \"toarray\"):\n",
    "            return X.toarray()\n",
    "        return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95ae27eb-71e0-4ae1-bec2-9061e65eb140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trained & saved: Logistic Regression\n",
      " Trained & saved: Decision Tree\n",
      " Trained & saved: KNN\n",
      " Trained & saved: Naive Bayes (Gaussian)\n",
      " Trained & saved: Random Forest\n",
      " Trained & saved: XGBoost\n",
      "\n",
      "===== METRICS COMPARISON TABLE =====\n",
      "                 Model  Accuracy      AUC  Precision   Recall       F1      MCC\n",
      "               XGBoost  0.909543 0.935327   0.655440 0.478261 0.553005 0.511802\n",
      "         Random Forest  0.907332 0.929098   0.669753 0.410208 0.508792 0.477797\n",
      "   Logistic Regression  0.901250 0.905574   0.644483 0.347826 0.451811 0.426058\n",
      "                   KNN  0.898596 0.850027   0.625668 0.331758 0.433601 0.407007\n",
      "Naive Bayes (Gaussian)  0.854805 0.810080   0.405904 0.519849 0.455864 0.377358\n",
      "         Decision Tree  0.874599 0.701457   0.464880 0.475425 0.470093 0.399021\n",
      "\n",
      "===== BEST MODEL: XGBoost =====\n",
      "Confusion Matrix:\n",
      "[[7719  266]\n",
      " [ 552  506]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      7985\n",
      "           1       0.66      0.48      0.55      1058\n",
      "\n",
      "    accuracy                           0.91      9043\n",
      "   macro avg       0.79      0.72      0.75      9043\n",
      "weighted avg       0.90      0.91      0.90      9043\n",
      "\n",
      "\n",
      " Saved metrics table to: model/model_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c902b4a8-df64-405b-ab8e-cc0dc8557c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\navneet kang\\appdata\\roaming\\python\\python312\\site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf13ff-3412-44be-9cb0-0bf8ed0a44a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
